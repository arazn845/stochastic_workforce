using JuMP
using NLPModelsJuMP, NLPModels
using GLPK
using Distributions
using Random
using DataFrames
using CSV
using Printf

function print_iteration(k, args...)
    f(x) = Printf.@sprintf("%12.4e", x)
    println(lpad(k, 9), " ", join(f.(args), " "))
    return
end

###############################################################
# PARAMETERS
###############################################################
H = 4
J = 3
Táµˆ = 1
TË¢ = 1
Î = 1

s = [1.0  0.0  0.0;  0.0  1.0  0.0; 0.0  0.0  1.0; 1.0  0.0  0.0]

Ïˆ = [ 1 0 0 ; 0 1 0 ; 0 0 1 ; 1 0 0 ];
Ï‡ = zeros(H,J);
d = [
    0.7  0.8  0.8  0.6  0.9  1.0  1.0  0.9  0.0  1.0
    0.2  0.2  1.0  0.9  0.7  0.7  0.4  1.0  0.3  0.7
    0.5  0.6  0.5  0.1  0.4  0.6  0.4  0.0  0.5  0.6
    0.5  1.4  0.3  1.0  0.8  0.8  0.2  0.8  0.6  0.6
    0.8  0.2  1.3  0.6  0.3  0.4  0.6  0.8  0.4  0.8
    0.3  0.4  0.9  0.2  0.6  1.0  0.4  0.3  0.4  0.6
]


Random.seed!(1234)

Î¼ = [1.2, 0.8, 0.6]

Î£ = [0.5 0.0 0.0;
     0.0 0.5 0.0;
     0.0 0.0 0.5
    ]

dÎ¾ = reshape(rand(MvNormal(Î¼,Î£), Î ), (J,TË¢,Î) )
dÎ¾ = round.(dÎ¾ , digits = 2)

Ï‡áµáµƒË£ = fill(1, H ,J)


záµ– = [7; 9; 11;7 ] * 1000
zá¶œ = záµ– *2

záµ = fill(0, H, J)

for h=1
        záµ[h , 2] = (1/2) * záµ–[h]
        záµ[h , 3] = (3/4) * záµ–[h]
end

for h=2
        záµ[h , 3] = (1/2) * záµ–[h]
        záµ[h , 1] = (3/4) * záµ–[h]
end

for h=3
        záµ[h , 1] = (1/2) * záµ–[h]
        záµ[h , 2] = (3/4) * záµ–[h]
end

for h=4
        záµ[h , 2] = (1/2) * záµ–[h]
        záµ[h , 3] = (3/4) * záµ–[h]
end

;


#########################################
# main model
#########################################

main = Model(GLPK.Optimizer)
@variable(main, Ïˆ[1:H , 1:J], Bin)
@variable(main, 0 â‰¤ Ï‡[1:H , 1:J])
@variable(main, Î±[1:H , 1:J , 1:Táµˆ], Bin)
@variable(main, -1000000 â‰¤ Î¸)

@variable(main, z1[1:H , 1:J , 1:Táµˆ], Bin)
@variable(main, z2[1:H , 1:J , 1:Táµˆ])

@objective(main, Min, sum( záµ–[h] * Ïˆ[h,j] * (Táµˆ + TË¢) + záµ[h,j] * Ï‡[h,j] 
                           for h in 1:H for j in 1:J) + Î¸);


#con1_s1 = @NLconstraint(main, demand_met[j in 1:J , t in 1:Táµˆ], 
#                          sum(  Î±[h,j,t] *(Ïˆ[h,j] + Ï‡[h,j]) for h in 1:H ) â‰¥ d[j,t] );

#################
# LINEARIZING
#################
@constraint(main, linear1[h = 1:H , j = 1:J , t =1:Táµˆ], z1[h,j,t] â‰¤ Î±[h,j,t] )
@constraint(main, linear2[h = 1:H , j = 1:J , t =1:Táµˆ], z1[h,j,t] â‰¤ Ïˆ[h,j] )
@constraint(main, linear3[h = 1:H , j = 1:J , t =1:Táµˆ], z1[h,j,t] â‰¥ Î±[h,j,t] + Ïˆ[h,j] -1 )

@constraint(main, linear4[h = 1:H , j = 1:J , t =1:Táµˆ], z2[h,j,t] â‰¤ Î±[h,j,t] )
@constraint(main, linear5[h = 1:H , j = 1:J , t =1:Táµˆ], z2[h,j,t] â‰¤ Ï‡[h,j] )
@constraint(main, linear6[h = 1:H , j = 1:J , t =1:Táµˆ], z2[h,j,t] â‰¥ Î±[h,j,t] + Ï‡[h,j] -1 )

con1_s1 = @constraint(main, demand_met[ j in 1:J , t in 1:Táµˆ ], 
    sum(z1[h,j,t] + z2[h,j,t] for h in 1:H ) â‰¥ d[j,t] );

con2_s1 = @constraint(main, permanent_pool[h in 1:H , j in 1:J], Ïˆ[h,j] â‰¤ s[h,j]);

con3_s1 = @constraint(main, allocation_recruitment_training[h in 1:H , j in 1:J , t in 1:Táµˆ],
                      Î±[h,j,t] â‰¤ Ïˆ[h,j] + 10 * Ï‡[h,j] );

con4_s1 = @constraint(main, no_more_than_one_station[h in 1:H , t in 1:Táµˆ],
              sum(Î±[h,j,t] for j in 1:J) â‰¤ 1  )

con4_s1 = @constraint(main, single_skilling_at_recruitment[h in 1:H , j in 1:J], 
    Ï‡[h,j] â‰¤ ( 1 - Ïˆ[h,j] ) * Ï‡áµáµƒË£[h,j] );

con5_s1 = @constraint(main, training_recruited[ h in 1:H ], 
    sum(Ï‡[h,j] for j in 1:J ) â‰¤ sum(Ïˆ[h,j] for j in 1:J) * J  );



################################################
# this function optimize the sub problem and generates the value for Î±_{h,j,t,Î¾}
################################################

function sub_for_Î±(Ïˆ , Ï‡)
    sub = Model(GLPK.Optimizer)
    @variable(sub, Î±[1:H , 1:J , 1:TË¢ , 1:Î], Bin )
    @variable(sub, 0 â‰¤ Î³[1:J , 1:TË¢ , 1:Î]);
    @objective(sub, Min,  (1/Î) * sum(zá¶œ[j] * Î³[j,t,Î¾] for j in 1:J for t in 1:TË¢ for Î¾ in 1:Î) )
    con1_S2 = @constraint(sub, demand_met[ j in 1:J , t in 1:TË¢ , Î¾ in 1:Î],
     sum(Î±[h,j,t,Î¾] * (Ïˆ[h,j] + Ï‡[h,j]) for h in 1:H ) + Î³[j,t,Î¾] â‰¥ dÎ¾[j,t,Î¾]  );
    con2_s2 = @constraint(sub, permanent_allocability[h in 1:H , j in 1:J , t in 1:TË¢ , Î¾ in 1:Î],
            Î±[h,j,t,Î¾] â‰¤ Ïˆ[h,j] + 10 * Ï‡[h,j] );
    con3_s2 = @constraint(sub, no_more_than_one_station[h in 1:H , t in 1:TË¢ , Î¾ in 1:Î],
           sum( Î±[h,j,t,Î¾] for j in 1:J) â‰¤ 1 );
    optimize!(sub)
    Î± = value.(Î±)
    Î³ = value.(Î³)
    o = objective_value(sub)
    Î± = round.(Î± , digits = 2)
    Î³ = round.(Î³ , digits = 2)
    o = round.(o , digits = 2)
    return (Î± , Î³ , o)
end

@show sub_for_Î±(Ïˆ , Ï‡)[1]
@show sub_for_Î±(Ïˆ , Ï‡)[2]
@show sub_for_Î±(Ïˆ , Ï‡)[3]

################################################################
# defining a function for second stage integer dual
###########################################

# when we want to get the dual the x (first stage variables are considered as fixed)
# when we want to get the coefficents of x, x should be variable
# therefore, we need to define two models one for dual and one for coefficient
###########################################
###############################################################

l = sub_for_Î±(Ïˆ , Ï‡)[1]


function sub_dual(Ïˆ , Ï‡)
    sub_for_dual = Model(GLPK.Optimizer) 
    @variable(sub_for_dual,  Î±[1:H,1:J,1:TË¢ , 1:Î])
    @variable(sub_for_dual, 0 â‰¤ Î³[1:J , 1:TË¢ , 1:Î])
    @objective(sub_for_dual, Min,  sum(zá¶œ[j] * Î³[j,t,Î¾] for j in 1:J for t in 1:TË¢ for Î¾ in 1:Î ) )
    for h in 1:H
            for j in 1:J
                for t in 1:TË¢
                    for Î¾ in 1:Î
                        if l[h,j,t,Î¾] == 0
                            con = @constraint(sub_for_dual, Î±[h,j,t,Î¾] == 0)
                        else
                            con = @constraint(sub_for_dual, Î±[h,j,t,Î¾] == 1)
                        end
                    end
                end
            end
        end

    con1_S2 = @constraint(sub_for_dual, demand_met[ j in 1:J , t in 1:TË¢ , Î¾ in 1:Î],
         dÎ¾[j,t,Î¾] â‰¤ sum(Î±[h,j,t,Î¾] * (Ïˆ[h,j] + Ï‡[h,j]) for h in 1:H ) + Î³[j,t,Î¾]   )
    con2_s2 = @constraint(sub_for_dual, permanent_allocability[h in 1:H , j in 1:J , t in 1:TË¢ , Î¾ in 1:Î],
                Î±[h,j,t,Î¾] â‰¤ Ïˆ[h,j] + 10 * Ï‡[h,j] );
    con3_s2 = @constraint(sub_for_dual, no_more_than_one_station[h in 1:H , t in 1:TË¢ , Î¾ in 1:Î],
               sum( Î±[h,j,t,Î¾] for j in 1:J) â‰¤ 1 );
    optimize!(sub_for_dual)
   #print(sub_for_dual)

    con_equal = all_constraints(sub_for_dual, AffExpr, MOI.EqualTo{Float64})
    con_less = all_constraints(sub_for_dual, AffExpr, MOI.LessThan{Float64})
    Î»1 = dual.(con_equal)
    Î»2 = dual.(con_less)
    Î» = append!(Î»1 , Î»2)

    no_con_equal = length(con_equal)
    no_con_less = length(con_less)
    no_all_con = no_con_equal + no_con_less;
    @show no_con_equal
    @show no_con_less
    @show no_all_con;
    
    return Î»
end

sub_dual(Ïˆ , Ï‡);

#############################################
# function for coefficients of  ğœ“  and  ğœ’
#############################################

function sub_coeff(Ïˆ , Ï‡)   
    sub_for_coeff = Model(GLPK.Optimizer) 
    @variable(sub_for_coeff,     Ïˆ[1:H , 1:J], Bin )
    @variable(sub_for_coeff, 0 â‰¤ Ï‡[1:H , 1:J])
    @variable(sub_for_coeff,  Î±[1:H, 1:J , 1:TË¢, 1:Î])
    @variable(sub_for_coeff, 0 â‰¤ Î³[1:J , 1:TË¢ , 1:Î])
    @objective(sub_for_coeff, Min,  sum(zá¶œ[j] * Î³[j,t,Î¾] for j in 1:J for t in 1:TË¢ for Î¾ in 1:Î ) )
    for h in 1:H
            for j in 1:J
                for t in 1:TË¢
                    for Î¾ in 1:Î
                        if l[h,j,t,Î¾] == 0
                            con = @constraint(sub_for_coeff, Î±[h,j,t,Î¾] == 0)
                        else
                            con = @constraint(sub_for_coeff, Î±[h,j,t,Î¾] == 1)
                        end
                    end
                end
            end
        end

    con1_S2 = @NLconstraint(sub_for_coeff, demand_met[ j in 1:J , t in 1:TË¢ , Î¾ in 1:Î],
         dÎ¾[j,t,Î¾] â‰¤ sum(Î±[h,j,t,Î¾] * (Ïˆ[h,j] + Ï‡[h,j]) for h in 1:H ) + Î³[j,t,Î¾]   )
    con2_s2 = @constraint(sub_for_coeff, permanent_allocability[h in 1:H , j in 1:J , t in 1:TË¢ , Î¾ in 1:Î],
                Î±[h,j,t,Î¾] â‰¤ Ïˆ[h,j] + 10 * Ï‡[h,j] );
    con3_s2 = @constraint(sub_for_coeff, no_more_than_one_station[h in 1:H , t in 1:TË¢ , Î¾ in 1:Î],
               sum( Î±[h,j,t,Î¾] for j in 1:J) â‰¤ 1 );

    vr = all_variables(sub_for_coeff)
    vr_index = [vr[i].index.value for i in 1:length(vr)]
    df = DataFrame(variable = vr , index = vr_index); 
    #@show df
    
    nlp = MathOptNLPModel(sub_for_coeff)
    q = zeros(nlp.meta.nvar)
    jac(nlp, q)
    A1 = jac(nlp, q)[ : , 1:24]
    return A1
end

sub_coeff(Ïˆ , Ï‡)   

println("        k  upper bound   lower bound  gap")
for k = 1:10
    optimize!(main)
    lb = objective_value(main)
    Ïˆ = value.(Ïˆ)
    Ï‡ = value.(Ï‡)
    Î³ = value.(sub_for_Î±(Ïˆ , Ï‡)[2] )
    Î» = sub_dual(Ïˆ , Ï‡)
    A1 = sub_coeff(Ïˆ , Ï‡)
    ub = sum( záµ–[h] * Ïˆ[h,j] * (Táµˆ + TË¢) + záµ[h,j] * Ï‡[h,j]   for h in 1:H for j in 1:J) + 
        (1/Î) * sum(zá¶œ[j] * Î³[j,t,Î¾] for j in 1:J for t in 1:TË¢ for Î¾ in 1:Î)      
    gap = (ub - lb) / ub
    print_iteration(k ,lb , ub , gap)
    if gap < 0.00001
        println("###### we are at optimality  #######")
        break
    end
    cut = @constraint(main, Î¸ â‰¥ (sub_for_Î±(Ïˆ, Ï‡))[3] - Î»' * A1 * (x .- value.(x) ) )
    println("we adding the $(cut)")

    @info "we adding the $(cut)"
end
